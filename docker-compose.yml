# Local development stack: db + backend + frontend + optional vLLM profile.

services:
  db:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: appdb
    ports:
      - "5433:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
      - ./db/init:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d appdb"]
      interval: 5s
      timeout: 3s
      retries: 10

  backend:
    build:
      context: ../ketchup-backend
      dockerfile: Dockerfile
    env_file:
      - ./.env
    volumes:
      - ../ketchup-backend:/app
    environment:
      DATABASE_URL: postgresql://postgres:postgres@db:5432/appdb
      VLLM_BASE_URL: ${VLLM_BASE_URL:-http://vllm-local:8080/v1}
      VLLM_MODEL: ${VLLM_MODEL:-Qwen/Qwen3-4B-Instruct-2507}
      VLLM_API_KEY: ${VLLM_API_KEY:-EMPTY}
      PLANNER_NOVELTY_TARGET_GENERATE: ${PLANNER_NOVELTY_TARGET_GENERATE:-0.7}
      PLANNER_NOVELTY_TARGET_REFINE: ${PLANNER_NOVELTY_TARGET_REFINE:-0.35}
      PLANNER_FALLBACK_ENABLED: ${PLANNER_FALLBACK_ENABLED:-true}
      BACKEND_INTERNAL_API_KEY: ${BACKEND_INTERNAL_API_KEY:-dev-internal-key-change-me}
      CORS_ORIGINS: '["http://localhost:3001","http://frontend:3001"]'
      FRONTEND_URL: ${FRONTEND_URL:-http://localhost:3001}
    command: uvicorn api.main:app --host 0.0.0.0 --port 8000
    depends_on:
      db:
        condition: service_healthy
    restart: unless-stopped

  frontend:
    image: node:22-alpine
    working_dir: /app
    env_file:
      - ./.env
    ports:
      - "3001:3001"
    volumes:
      - ../ketchup-frontend:/app
      - frontend_node_modules:/app/node_modules
    environment:
      AUTH_URL: http://localhost:3001
      NEXTAUTH_URL: http://localhost:3001
      BACKEND_URL: http://backend:8000
      BACKEND_INTERNAL_API_KEY: ${BACKEND_INTERNAL_API_KEY:-dev-internal-key-change-me}
      WATCHPACK_POLLING: "true"
    command: sh -c "npm install && npm run dev"
    depends_on:
      - backend
    restart: unless-stopped

  # Optional local vLLM profiles:
  # docker compose --profile llm-apple up --build
  # docker compose --profile llm-nvidia up --build
  # docker compose --profile llm-rocm up --build
  vllm-apple-bridge:
    profiles: ["llm-apple"]
    image: alpine/socat:latest
    command:
      - tcp-listen:8080,fork,reuseaddr
      - tcp-connect:host.docker.internal:8080
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      default:
        aliases:
          - vllm-local
    healthcheck:
      test: ["CMD", "nc", "-z", "host.docker.internal", "8080"]
      interval: 10s
      start_period: 5s
      timeout: 3s
      retries: 20

  vllm-nvidia:
    profiles: ["llm-nvidia"]
    image: vllm/vllm-openai:latest
    gpus: all
    ports:
      - "8080:8080"
    shm_size: "8gb"
    volumes:
      - ./models/hf-cache:/root/.cache/huggingface
    networks:
      default:
        aliases:
          - vllm-local
    environment:
      HF_TOKEN: ${HF_TOKEN:-}
    command:
      - --model
      - ${VLLM_MODEL_HF_ID:-Qwen/Qwen3-4B-Instruct-2507}
      - --host
      - 0.0.0.0
      - --port
      - "8080"
      - --max-model-len
      - ${VLLM_MAX_MODEL_LEN:-4096}
      - --max-num-seqs
      - ${VLLM_MAX_NUM_SEQS:-4}
      - --enable-auto-tool-choice
      - --tool-call-parser
      - ${VLLM_TOOL_CALL_PARSER:-hermes}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      start_period: 60s
      timeout: 5s
      retries: 10

  vllm-rocm:
    profiles: ["llm-rocm"]
    image: vllm/vllm-openai-rocm:latest
    group_add:
      - video
    cap_add:
      - SYS_PTRACE
    security_opt:
      - seccomp=unconfined
    devices:
      - /dev/kfd
      - /dev/dri
    ports:
      - "8080:8080"
    shm_size: "8gb"
    volumes:
      - ./models/hf-cache:/root/.cache/huggingface
    networks:
      default:
        aliases:
          - vllm-local
    environment:
      HF_TOKEN: ${HF_TOKEN:-}
    command:
      - --model
      - ${VLLM_MODEL_HF_ID:-Qwen/Qwen3-4B-Instruct-2507}
      - --host
      - 0.0.0.0
      - --port
      - "8080"
      - --max-model-len
      - ${VLLM_MAX_MODEL_LEN:-4096}
      - --max-num-seqs
      - ${VLLM_MAX_NUM_SEQS:-4}
      - --enable-auto-tool-choice
      - --tool-call-parser
      - ${VLLM_TOOL_CALL_PARSER:-hermes}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      start_period: 60s
      timeout: 5s
      retries: 10

volumes:
  pgdata:
  frontend_node_modules:
